{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v4.json", "dbt_version": "1.0.0", "generated_at": "2025-03-05T17:54:00.850074Z", "invocation_id": "7bda017a-bdde-4995-8cbc-854daa40a079", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:41:51.322003Z", "completed_at": "2025-03-05T17:41:51.329331Z"}, {"name": "execute", "started_at": "2025-03-05T17:41:51.329813Z", "completed_at": "2025-03-05T17:42:00.476966Z"}], "thread_id": "Thread-1", "execution_time": 9.157549381256104, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_artists"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:42:00.480752Z", "completed_at": "2025-03-05T17:42:00.488416Z"}, {"name": "execute", "started_at": "2025-03-05T17:42:00.488810Z", "completed_at": "2025-03-05T17:42:10.234940Z"}], "thread_id": "Thread-1", "execution_time": 9.756725788116455, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_locations"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:42:10.239185Z", "completed_at": "2025-03-05T17:42:10.242447Z"}, {"name": "execute", "started_at": "2025-03-05T17:42:10.242732Z", "completed_at": "2025-03-05T17:42:26.625479Z"}], "thread_id": "Thread-1", "execution_time": 16.390762090682983, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_sessions"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:42:26.633878Z", "completed_at": "2025-03-05T17:42:26.640887Z"}, {"name": "execute", "started_at": "2025-03-05T17:42:26.641120Z", "completed_at": "2025-03-05T17:43:01.193998Z"}], "thread_id": "Thread-1", "execution_time": 34.56347322463989, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_songs"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:43:01.204013Z", "completed_at": "2025-03-05T17:43:01.210412Z"}, {"name": "execute", "started_at": "2025-03-05T17:43:01.211983Z", "completed_at": "2025-03-05T17:47:15.417900Z"}], "thread_id": "Thread-1", "execution_time": 254.22060537338257, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_time"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:47:15.423821Z", "completed_at": "2025-03-05T17:47:15.430411Z"}, {"name": "execute", "started_at": "2025-03-05T17:47:15.430791Z", "completed_at": "2025-03-05T17:47:40.588193Z"}], "thread_id": "Thread-1", "execution_time": 25.17044758796692, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.dim_users"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:47:40.597911Z", "completed_at": "2025-03-05T17:47:40.607468Z"}, {"name": "execute", "started_at": "2025-03-05T17:47:40.608145Z", "completed_at": "2025-03-05T17:47:50.105833Z"}], "thread_id": "Thread-1", "execution_time": 9.513442516326904, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.fact_auth_events"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:47:50.111401Z", "completed_at": "2025-03-05T17:47:50.119037Z"}, {"name": "execute", "started_at": "2025-03-05T17:47:50.119433Z", "completed_at": "2025-03-05T17:49:41.125729Z"}], "thread_id": "Thread-1", "execution_time": 111.01724100112915, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.fact_listen_events"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:49:41.135171Z", "completed_at": "2025-03-05T17:49:41.139430Z"}, {"name": "execute", "started_at": "2025-03-05T17:49:41.139777Z", "completed_at": "2025-03-05T17:51:12.797466Z"}], "thread_id": "Thread-1", "execution_time": 91.66929149627686, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.fact_page_views"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:12.806156Z", "completed_at": "2025-03-05T17:51:12.810024Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:12.810382Z", "completed_at": "2025-03-05T17:51:20.134022Z"}], "thread_id": "Thread-1", "execution_time": 7.3346474170684814, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.fact_status_changes"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:20.142659Z", "completed_at": "2025-03-05T17:51:20.149218Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:20.149513Z", "completed_at": "2025-03-05T17:51:21.883320Z"}], "thread_id": "Thread-1", "execution_time": 1.7470378875732422, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_avg_session_duration"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:21.888496Z", "completed_at": "2025-03-05T17:51:21.899806Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:21.900094Z", "completed_at": "2025-03-05T17:51:39.786927Z"}], "thread_id": "Thread-1", "execution_time": 17.90092658996582, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_city_active_users"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:39.790660Z", "completed_at": "2025-03-05T17:51:39.797299Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:39.797624Z", "completed_at": "2025-03-05T17:51:43.270608Z"}], "thread_id": "Thread-1", "execution_time": 3.4834299087524414, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_daily_user_song_count"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:43.277324Z", "completed_at": "2025-03-05T17:51:43.285730Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:43.286298Z", "completed_at": "2025-03-05T17:51:47.908608Z"}], "thread_id": "Thread-1", "execution_time": 4.6341753005981445, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_free_vs_paid_users"}, {"status": "error", "timing": [], "thread_id": "Thread-1", "execution_time": 0.09301328659057617, "adapter_response": {}, "message": "Runtime Error in model report_new_user_behavior (models/gold/report_new_user_behavior.sql)\n  Database Error\n    org.apache.hive.service.cli.HiveSQLException: Error running query: [INVALID_PARAMETER_VALUE.DATETIME_UNIT] org.apache.spark.sql.catalyst.parser.ParseException: \n    [INVALID_PARAMETER_VALUE.DATETIME_UNIT] The value of parameter(s) `unit` in `date_diff` is invalid: expects one of the units without quotes YEAR, QUARTER, MONTH, WEEK, DAY, DAYOFYEAR, HOUR, MINUTE, SECOND, MILLISECOND, MICROSECOND, but got the string literal 'day'.(line 27, pos 8)\n    \n    == SQL ==\n    /* {\"app\": \"dbt\", \"dbt_version\": \"1.0.0\", \"profile_name\": \"spotify_analytics\", \"target_name\": \"dev\", \"node_id\": \"model.spotify_analytics.report_new_user_behavior\"} */\n    \n          create table default_gold.report_new_user_behavior\n        \n        \n        using parquet\n        \n        \n        \n        \n        location 'hdfs://namenode:9000/user/gold/report_new_user_behavior'\n        \n        as\n          \n    \n    \n    with new_users as (\n        select\n            user_id,\n            registration_timestamp\n        from default_silver.dim_users\n    ),\n    \n    first_week_activity as (\n        select\n            f.user_id,\n            date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp) as days_since_registration,\n    --------^^^\n            count(*) as song_plays,\n            count(distinct f.session_id) as sessions,\n            sum(f.duration_seconds) as total_listening_time\n        from default_silver.fact_listen_events f\n        join new_users u on f.user_id = u.user_id\n        where date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp) between 0 and 7\n        group by f.user_id, date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp)\n    )\n    \n    select\n        user_id,\n        days_since_registration,\n        song_plays as daily_song_plays,\n        sessions as daily_sessions,\n        total_listening_time as daily_listening_time_seconds,\n        total_listening_time / 60 as daily_listening_time_minutes\n    from first_week_activity\n    order by user_id, days_since_registration\n    \n    \tat org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:43)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:263)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:167)\n    \tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:41)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:167)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:162)\n    \tat java.base/java.security.AccessController.doPrivileged(Unknown Source)\n    \tat java.base/javax.security.auth.Subject.doAs(Unknown Source)\n    \tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:176)\n    \tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\n    \tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    \tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    \tat java.base/java.lang.Thread.run(Unknown Source)\n    Caused by: org.apache.spark.sql.catalyst.parser.ParseException: \n    [INVALID_PARAMETER_VALUE.DATETIME_UNIT] The value of parameter(s) `unit` in `date_diff` is invalid: expects one of the units without quotes YEAR, QUARTER, MONTH, WEEK, DAY, DAYOFYEAR, HOUR, MINUTE, SECOND, MILLISECOND, MICROSECOND, but got the string literal 'day'.(line 27, pos 8)\n    \n    == SQL ==\n    /* {\"app\": \"dbt\", \"dbt_version\": \"1.0.0\", \"profile_name\": \"spotify_analytics\", \"target_name\": \"dev\", \"node_id\": \"model.spotify_analytics.report_new_user_behavior\"} */\n    \n          create table default_gold.report_new_user_behavior\n        \n        \n        using parquet\n        \n        \n        \n        \n        location 'hdfs://namenode:9000/user/gold/report_new_user_behavior'\n        \n        as\n          \n    \n    \n    with new_users as (\n        select\n            user_id,\n            registration_timestamp\n        from default_silver.dim_users\n    ),\n    \n    first_week_activity as (\n        select\n            f.user_id,\n            date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp) as days_since_registration,\n    --------^^^\n            count(*) as song_plays,\n            count(distinct f.session_id) as sessions,\n            sum(f.duration_seconds) as total_listening_time\n        from default_silver.fact_listen_events f\n        join new_users u on f.user_id = u.user_id\n        where date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp) between 0 and 7\n        group by f.user_id, date_diff('day', from_unixtime(u.registration_timestamp), f.listen_timestamp)\n    )\n    \n    select\n        user_id,\n        days_since_registration,\n        song_plays as daily_song_plays,\n        sessions as daily_sessions,\n        total_listening_time as daily_listening_time_seconds,\n        total_listening_time / 60 as daily_listening_time_minutes\n    from first_week_activity\n    order by user_id, days_since_registration\n    \n    \tat org.apache.spark.sql.errors.QueryParsingErrors$.invalidDatetimeUnitError(QueryParsingErrors.scala:668)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitTimestampdiff$1(AstBuilder.scala:5041)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitTimestampdiff(AstBuilder.scala:5037)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitTimestampdiff(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$TimestampdiffContext.accept(SqlBaseParser.java:18979)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitChildren(AstBuilder.scala:129)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParserBaseVisitor.visitValueExpressionDefault(SqlBaseParserBaseVisitor.java:1630)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$ValueExpressionDefaultContext.accept(SqlBaseParser.java:18127)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.expression(AstBuilder.scala:1774)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitPredicated$1(AstBuilder.scala:1910)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitPredicated(AstBuilder.scala:1909)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitPredicated(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$PredicatedContext.accept(SqlBaseParser.java:17545)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitChildren(AstBuilder.scala:129)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParserBaseVisitor.visitExpression(SqlBaseParserBaseVisitor.java:1567)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$ExpressionContext.accept(SqlBaseParser.java:17288)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.expression(AstBuilder.scala:1774)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitNamedExpression$1(AstBuilder.scala:1796)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitNamedExpression(AstBuilder.scala:1795)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitNamedExpression(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$NamedExpressionContext.accept(SqlBaseParser.java:16790)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitNamedExpressionSeq$2(AstBuilder.scala:761)\n    \tat scala.collection.immutable.List.map(List.scala:297)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitNamedExpressionSeq(AstBuilder.scala:761)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$withSelectQuerySpecification$1(AstBuilder.scala:870)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.withSelectQuerySpecification(AstBuilder.scala:864)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitRegularQuerySpecification$1(AstBuilder.scala:745)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitRegularQuerySpecification(AstBuilder.scala:733)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitRegularQuerySpecification(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$RegularQuerySpecificationContext.accept(SqlBaseParser.java:10650)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitChildren(AstBuilder.scala:129)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParserBaseVisitor.visitQueryPrimaryDefault(SqlBaseParserBaseVisitor.java:923)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryPrimaryDefaultContext.accept(SqlBaseParser.java:10155)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitChildren(AstBuilder.scala:129)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParserBaseVisitor.visitQueryTermDefault(SqlBaseParserBaseVisitor.java:909)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryTermDefaultContext.accept(SqlBaseParser.java:9922)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:170)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitQuery$1(AstBuilder.scala:176)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitQuery(AstBuilder.scala:175)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitQuery(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryContext.accept(SqlBaseParser.java:6912)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:170)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitNamedQuery$1(AstBuilder.scala:254)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitNamedQuery(AstBuilder.scala:253)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$withCTE$1(AstBuilder.scala:190)\n    \tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n    \tat scala.collection.Iterator.foreach(Iterator.scala:943)\n    \tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n    \tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n    \tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n    \tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n    \tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n    \tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n    \tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n    \tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.withCTE(AstBuilder.scala:189)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitQuery$3(AstBuilder.scala:179)\n    \tat org.apache.spark.sql.catalyst.parser.package$EnhancedLogicalPlan$.optionalMap$extension(package.scala:42)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitQuery$1(AstBuilder.scala:179)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitQuery(AstBuilder.scala:175)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitQuery(AstBuilder.scala:60)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$QueryContext.accept(SqlBaseParser.java:6912)\n    \tat org.apache.spark.sql.catalyst.parser.DataTypeAstBuilder.typedVisit(DataTypeAstBuilder.scala:34)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.plan(AstBuilder.scala:170)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCreateTable$6(AstBuilder.scala:3908)\n    \tat scala.Option.map(Option.scala:230)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitCreateTable$1(AstBuilder.scala:3908)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitCreateTable(AstBuilder.scala:3883)\n    \tat org.apache.spark.sql.execution.SparkSqlAstBuilder.super$visitCreateTable(SparkSqlParser.scala:315)\n    \tat org.apache.spark.sql.execution.SparkSqlAstBuilder.$anonfun$visitCreateTable$1(SparkSqlParser.scala:315)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.execution.SparkSqlAstBuilder.visitCreateTable(SparkSqlParser.scala:311)\n    \tat org.apache.spark.sql.execution.SparkSqlAstBuilder.visitCreateTable(SparkSqlParser.scala:61)\n    \tat org.apache.spark.sql.catalyst.parser.SqlBaseParser$CreateTableContext.accept(SqlBaseParser.java:1712)\n    \tat org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visit(AbstractParseTreeVisitor.java:18)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.$anonfun$visitSingleStatement$1(AstBuilder.scala:136)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AstBuilder.visitSingleStatement(AstBuilder.scala:136)\n    \tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$2(AbstractSqlParser.scala:71)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin(SparkParserUtils.scala:125)\n    \tat org.apache.spark.sql.catalyst.util.SparkParserUtils.withOrigin$(SparkParserUtils.scala:115)\n    \tat org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(ParserUtils.scala:32)\n    \tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.$anonfun$parsePlan$1(AbstractSqlParser.scala:71)\n    \tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:80)\n    \tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:54)\n    \tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:68)\n    \tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:684)\n    \tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n    \tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:683)\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:682)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:713)\n    \tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:744)\n    \tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651)\n    \tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:228)\n    \t... 16 more\n    ", "failures": null, "unique_id": "model.spotify_analytics.report_new_user_behavior"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:51:48.006235Z", "completed_at": "2025-03-05T17:51:48.010409Z"}, {"name": "execute", "started_at": "2025-03-05T17:51:48.010706Z", "completed_at": "2025-03-05T17:53:06.010591Z"}], "thread_id": "Thread-1", "execution_time": 78.00695466995239, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_top_songs"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:53:06.015750Z", "completed_at": "2025-03-05T17:53:06.024149Z"}, {"name": "execute", "started_at": "2025-03-05T17:53:06.024456Z", "completed_at": "2025-03-05T17:53:26.982786Z"}], "thread_id": "Thread-1", "execution_time": 20.969499588012695, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_weekday_avg_listening_time"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:53:26.987292Z", "completed_at": "2025-03-05T17:53:26.991711Z"}, {"name": "execute", "started_at": "2025-03-05T17:53:26.991994Z", "completed_at": "2025-03-05T17:53:52.338123Z"}], "thread_id": "Thread-1", "execution_time": 25.35668182373047, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_error_status_codes"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:53:52.345999Z", "completed_at": "2025-03-05T17:53:52.358895Z"}, {"name": "execute", "started_at": "2025-03-05T17:53:52.359212Z", "completed_at": "2025-03-05T17:53:57.462827Z"}], "thread_id": "Thread-1", "execution_time": 5.119643211364746, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_skipping_sessions"}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-03-05T17:53:57.468297Z", "completed_at": "2025-03-05T17:53:57.476201Z"}, {"name": "execute", "started_at": "2025-03-05T17:53:57.476524Z", "completed_at": "2025-03-05T17:54:00.796392Z"}], "thread_id": "Thread-1", "execution_time": 3.331299304962158, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.spotify_analytics.report_conversion_rate"}], "elapsed_time": 730.1058213710785, "args": {"write_json": true, "use_colors": true, "printer_width": 80, "version_check": true, "partial_parse": true, "static_parser": true, "profiles_dir": "/usr/app/profiles", "send_anonymous_usage_stats": true, "event_buffer_size": 100000, "which": "run", "rpc_method": "run", "indirect_selection": "eager"}}